{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbedc4d5",
   "metadata": {},
   "source": [
    "## 제목 : Pytorch Classification NN\n",
    "## 작성자 : 김수\n",
    "## 작성 일자 : 2022.02.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959eefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "torch.manual_seed(777)\n",
    "num_epoch = 1000\n",
    "Learning_Rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f88663",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.loadtxt(\"G:/공유 드라이브/연구실 폴더/분류대회/Training_data.csv\",delimiter=\",\")\n",
    "test_data = np.loadtxt(\"G:/공유 드라이브/연구실 폴더/분류대회/Test_Input.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597b7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98000, 12])\n",
      "torch.Size([98000, 4])\n",
      "torch.Size([42000, 12])\n",
      "torch.Size([42000, 4])\n",
      "torch.Size([60000, 12])\n",
      "torch.Size([98000, 12])\n",
      "torch.Size([98000, 4])\n",
      "torch.Size([42000, 12])\n",
      "torch.Size([42000, 4])\n",
      "torch.Size([60000, 12])\n"
     ]
    }
   ],
   "source": [
    "cut_line = int(training_data.shape[0]*0.7)\n",
    "x = training_data[:cut_line,:12]\n",
    "y = training_data[:cut_line,-4:]\n",
    "val_x = training_data[cut_line:,:12]\n",
    "val_y = training_data[cut_line:,-4:]\n",
    "\n",
    "test_x = test_data[:,:12]\n",
    "\n",
    "X = torch.tensor(x,dtype=torch.float32)\n",
    "Y = torch.reshape(torch.tensor(y,dtype=torch.float32),[y.shape[0],y.shape[1]])\n",
    "Y_not_one_hot_encoding = torch.argmax(Y,dim=1)\n",
    "\n",
    "Val_X = torch.tensor(val_x,dtype=torch.float32)\n",
    "Val_Y = torch.reshape(torch.tensor(val_y,dtype=torch.float32),[val_y.shape[0],val_y.shape[1]])\n",
    "Val_Y_not_one_hot_encoding = torch.argmax(Val_Y,dim=1)\n",
    "\n",
    "TEST = torch.tensor(test_x,dtype=torch.float32)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Val_X.shape)\n",
    "print(Val_Y.shape)\n",
    "print(TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e30c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss :  0 Loss :  tensor(1.3865) Accuracy :  tensor(0.2523) Val Loss :  tensor(1.3839) Val Accuracy :  tensor(0.2628)\n",
      "tensor(1.3865) Accuracy :  tensor(0.2523) Val Loss :  tensor(1.3839) Val Accuracy :  tensor(0.2628)\n",
      "10 Loss :  tensor(1.2361) Accuracy :  tensor(0.5063) Val Loss :  tensor(1.2032) Val Accuracy :  tensor(0.5153)\n",
      "10 Loss :  tensor(1.2361) Accuracy :  tensor(0.5063) Val Loss :  tensor(1.2032) Val Accuracy :  tensor(0.5153)\n",
      "20 Loss :  tensor(1.1371) Accuracy :  tensor(0.5822) Val Loss :  tensor(1.1301) Val Accuracy :  tensor(0.6100)\n",
      "20 Loss :  tensor(1.1371) Accuracy :  tensor(0.5822) Val Loss :  tensor(1.1301) Val Accuracy :  tensor(0.6100)\n",
      "30 Loss :  tensor(1.1029) Accuracy :  tensor(0.6821) Val Loss :  tensor(1.0954) Val Accuracy :  tensor(0.6739)\n",
      "30 Loss :  tensor(1.1029) Accuracy :  tensor(0.6821) Val Loss :  tensor(1.0954) Val Accuracy :  tensor(0.6739)\n",
      "40 Loss :  tensor(1.0750) Accuracy :  tensor(0.7154) Val Loss :  tensor(1.0781) Val Accuracy :  tensor(0.7147)\n",
      "40 Loss :  tensor(1.0750) Accuracy :  tensor(0.7154) Val Loss :  tensor(1.0781) Val Accuracy :  tensor(0.7147)\n",
      "50 Loss :  tensor(1.0605) Accuracy :  tensor(0.7114) Val Loss :  tensor(1.0613) Val Accuracy :  tensor(0.7064)\n",
      "50 Loss :  tensor(1.0605) Accuracy :  tensor(0.7114) Val Loss :  tensor(1.0613) Val Accuracy :  tensor(0.7064)\n",
      "60 Loss :  tensor(1.0174) Accuracy :  tensor(0.7356) Val Loss :  tensor(1.0142) Val Accuracy :  tensor(0.7385)\n",
      "60 Loss :  tensor(1.0174) Accuracy :  tensor(0.7356) Val Loss :  tensor(1.0142) Val Accuracy :  tensor(0.7385)\n",
      "70 Loss :  tensor(0.9978) Accuracy :  tensor(0.7326) Val Loss :  tensor(0.9914) Val Accuracy :  tensor(0.7408)\n",
      "70 Loss :  tensor(0.9978) Accuracy :  tensor(0.7326) Val Loss :  tensor(0.9914) Val Accuracy :  tensor(0.7408)\n",
      "80 Loss :  tensor(0.9879) Accuracy :  tensor(0.7495) Val Loss :  tensor(0.9810) Val Accuracy :  tensor(0.7576)\n",
      "80 Loss :  tensor(0.9879) Accuracy :  tensor(0.7495) Val Loss :  tensor(0.9810) Val Accuracy :  tensor(0.7576)\n",
      "90 Loss :  tensor(0.9716) Accuracy :  tensor(0.7719) Val Loss :  tensor(0.9730) Val Accuracy :  tensor(0.7735)\n",
      "90 Loss :  tensor(0.9716) Accuracy :  tensor(0.7719) Val Loss :  tensor(0.9730) Val Accuracy :  tensor(0.7735)\n",
      "100 Loss :  tensor(0.9635) Accuracy :  tensor(0.7844) Val Loss :  tensor(0.9637) Val Accuracy :  tensor(0.7821)\n",
      "100 Loss :  tensor(0.9635) Accuracy :  tensor(0.7844) Val Loss :  tensor(0.9637) Val Accuracy :  tensor(0.7821)\n",
      "110 Loss :  tensor(0.9715) Accuracy :  tensor(0.7702) Val Loss :  tensor(0.9732) Val Accuracy :  tensor(0.7703)\n",
      "110 Loss :  tensor(0.9715) Accuracy :  tensor(0.7702) Val Loss :  tensor(0.9732) Val Accuracy :  tensor(0.7703)\n",
      "120 Loss :  tensor(0.9589) Accuracy :  tensor(0.7868) Val Loss :  tensor(0.9607) Val Accuracy :  tensor(0.7848)\n",
      "120 Loss :  tensor(0.9589) Accuracy :  tensor(0.7868) Val Loss :  tensor(0.9607) Val Accuracy :  tensor(0.7848)\n",
      "130 Loss :  tensor(0.9515) Accuracy :  tensor(0.7949) Val Loss :  tensor(0.9512) Val Accuracy :  tensor(0.7941)\n",
      "130 Loss :  tensor(0.9515) Accuracy :  tensor(0.7949) Val Loss :  tensor(0.9512) Val Accuracy :  tensor(0.7941)\n",
      "140 Loss :  tensor(0.9460) Accuracy :  tensor(0.7990) Val Loss :  tensor(0.9462) Val Accuracy :  tensor(0.7984)\n",
      "140 Loss :  tensor(0.9460) Accuracy :  tensor(0.7990) Val Loss :  tensor(0.9462) Val Accuracy :  tensor(0.7984)\n",
      "150 Loss :  tensor(0.9515) Accuracy :  tensor(0.7947) Val Loss :  tensor(0.9456) Val Accuracy :  tensor(0.7981)\n",
      "150 Loss :  tensor(0.9515) Accuracy :  tensor(0.7947) Val Loss :  tensor(0.9456) Val Accuracy :  tensor(0.7981)\n",
      "160 Loss :  tensor(0.9559) Accuracy :  tensor(0.7904) Val Loss :  tensor(0.9641) Val Accuracy :  tensor(0.7794)\n",
      "160 Loss :  tensor(0.9559) Accuracy :  tensor(0.7904) Val Loss :  tensor(0.9641) Val Accuracy :  tensor(0.7794)\n",
      "170 Loss :  tensor(0.9523) Accuracy :  tensor(0.7968) Val Loss :  tensor(0.9529) Val Accuracy :  tensor(0.7981)\n",
      "170 Loss :  tensor(0.9523) Accuracy :  tensor(0.7968) Val Loss :  tensor(0.9529) Val Accuracy :  tensor(0.7981)\n",
      "180 Loss :  tensor(0.9486) Accuracy :  tensor(0.8017) Val Loss :  tensor(0.9495) Val Accuracy :  tensor(0.7989)\n",
      "180 Loss :  tensor(0.9486) Accuracy :  tensor(0.8017) Val Loss :  tensor(0.9495) Val Accuracy :  tensor(0.7989)\n",
      "190 Loss :  tensor(0.9377) Accuracy :  tensor(0.8089) Val Loss :  tensor(0.9397) Val Accuracy :  tensor(0.8068)\n",
      "190 Loss :  tensor(0.9377) Accuracy :  tensor(0.8089) Val Loss :  tensor(0.9397) Val Accuracy :  tensor(0.8068)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7620/1469035470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_not_one_hot_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7620/1469035470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_not_one_hot_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Binary Crossentropy 손실 = loss(x,y) = BCE\n",
    "# Binary Crossentropy 손실 = loss(x,y) = BCE\n",
    "model = nn.Sequential(nn.Linear(X.shape[1], 50),nn.ReLU(),nn.Dropout(p=0.3),\n",
    "                      nn.Linear(50, 75), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(75, 100), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(100, 150), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(150, 200), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(200, 150), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(150, 100), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(100, 50), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(50, 25), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "                      nn.Linear(25, Y.shape[1]), nn.Softmax())\n",
    "optimizer = optim.Adam(model.parameters() ,lr = Learning_Rate)\n",
    "Loss_fun = torch.nn.CrossEntropyLoss()\n",
    "Loss = np.zeros((num_epoch,1))\n",
    "Val_Loss = np.zeros((num_epoch,1))\n",
    "Accuracy = np.zeros((num_epoch,1))\n",
    "Val_Accuracy = np.zeros((num_epoch,1))\n",
    "#학습\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = Loss_fun(output,Y_not_one_hot_encoding)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Accuracy Calculate\n",
    "    output_not_one_hot_encoding=torch.argmax(output,dim=1)\n",
    "    accuracy = torch.divide(torch.count_nonzero(torch.eq(output_not_one_hot_encoding,\n",
    "                                                         Y_not_one_hot_encoding)),Y_not_one_hot_encoding.shape[0])\n",
    "    with torch.no_grad():\n",
    "        val_output = model(Val_X)\n",
    "        val_loss = Loss_fun(val_output,Val_Y)\n",
    "        val_output_not_one_hot_encoding=torch.argmax(val_output,dim=1)\n",
    "        val_accuracy = torch.divide(torch.count_nonzero(torch.eq(val_output_not_one_hot_encoding,\n",
    "                                                         Val_Y_not_one_hot_encoding)),Val_Y_not_one_hot_encoding.shape[0])\n",
    "    Loss[i,0] = loss.data\n",
    "    Accuracy[i,0] = accuracy\n",
    "    Val_Loss[i,0] = val_loss.data\n",
    "    Val_Accuracy[i,0] = val_accuracy\n",
    "    if i % 10 == 0:\n",
    "        print(i,\"Loss : \",loss.data,\"Accuracy : \",accuracy.data,\"Val Loss : \",val_loss.data,\"Val Accuracy : \",val_accuracy.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab11e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67852e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = model(TEST)\n",
    "Predict_not_one_hot_encoding = torch.argmax(Predict,dim=1)\n",
    "print(Predict_not_one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5dbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"G:/내 드라이브/연구실/PyTorch/5주차/Test_Predict.csv\",Predict_not_one_hot_encoding,delimiter=\",\",fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196785fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

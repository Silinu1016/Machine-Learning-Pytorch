{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbedc4d5",
   "metadata": {},
   "source": [
    "## 제목 : Pytorch Classification NN\n",
    "## 작성자 : 김수\n",
    "## 작성 일자 : 2022.02.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959eefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "torch.manual_seed(777)\n",
    "num_epoch = 1000\n",
    "Learning_Rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f88663",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.loadtxt(\"G:/공유 드라이브/연구실 폴더/분류대회/Training_data.csv\",delimiter=\",\")\n",
    "test_data = np.loadtxt(\"G:/공유 드라이브/연구실 폴더/분류대회/Test_Input.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597b7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98000, 1, 24])\n",
      "torch.Size([98000, 4])\n",
      "torch.Size([42000, 1, 24])\n",
      "torch.Size([42000, 4])\n",
      "torch.Size([60000, 1, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11380/1297795176.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_re = torch.reshape(torch.tensor(X,dtype=torch.float32),[X.shape[0],1,X.shape[1]])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11380/1297795176.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Val_X_re = torch.reshape(torch.tensor(Val_X,dtype=torch.float32),[Val_X.shape[0],1,Val_X.shape[1]])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11380/1297795176.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Val_Y_re = torch.reshape(torch.tensor(Val_Y,dtype=torch.float32),[Val_Y.shape[0],1,Val_Y.shape[1]])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11380/1297795176.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  TEST_re = torch.reshape(torch.tensor(TEST,dtype=torch.float32),[TEST.shape[0],1,TEST.shape[1]])\n"
     ]
    }
   ],
   "source": [
    "cut_line = int(training_data.shape[0]*0.7)\n",
    "x = training_data[:cut_line,:-4]\n",
    "y = training_data[:cut_line,-4:]\n",
    "val_x = training_data[cut_line:,:-4]\n",
    "val_y = training_data[cut_line:,-4:]\n",
    "\n",
    "test_x = test_data[:,:]\n",
    "\n",
    "X = torch.tensor(x,dtype=torch.float32)\n",
    "Y = torch.reshape(torch.tensor(y,dtype=torch.float32),[y.shape[0],y.shape[1]])\n",
    "Y_not_one_hot_encoding = torch.argmax(Y,dim=1)\n",
    "\n",
    "Val_X = torch.tensor(val_x,dtype=torch.float32)\n",
    "Val_Y = torch.reshape(torch.tensor(val_y,dtype=torch.float32),[val_y.shape[0],val_y.shape[1]])\n",
    "Val_Y_not_one_hot_encoding = torch.argmax(Val_Y,dim=1)\n",
    "\n",
    "TEST = torch.tensor(test_x,dtype=torch.float32)\n",
    "\n",
    "X_re = torch.reshape(torch.tensor(X,dtype=torch.float32),[X.shape[0],1,X.shape[1]])\n",
    "Y_re = torch.reshape(torch.tensor(y,dtype=torch.long),[Y.shape[0],Y.shape[1]])\n",
    "Val_X_re = torch.reshape(torch.tensor(Val_X,dtype=torch.float32),[Val_X.shape[0],1,Val_X.shape[1]])\n",
    "Val_Y_re = torch.reshape(torch.tensor(Val_Y,dtype=torch.float32),[Val_Y.shape[0],1,Val_Y.shape[1]])\n",
    "\n",
    "TEST_re = torch.reshape(torch.tensor(TEST,dtype=torch.float32),[TEST.shape[0],1,TEST.shape[1]])\n",
    "\n",
    "\n",
    "print(X_re.shape)\n",
    "print(Y.shape)\n",
    "print(Val_X_re.shape)\n",
    "print(Val_Y.shape)\n",
    "print(TEST_re.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e30c851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv1d(1, 40, kernel_size=(6,), stride=(1,))\n",
      "  (1): ReLU()\n",
      "  (2): Conv1d(40, 40, kernel_size=(3,), stride=(1,))\n",
      "  (3): ReLU()\n",
      "  (4): Conv1d(40, 40, kernel_size=(3,), stride=(1,))\n",
      "  (5): ReLU()\n",
      "  (6): Conv1d(40, 40, kernel_size=(3,), stride=(1,))\n",
      "  (7): ReLU()\n",
      "  (8): Conv1d(40, 1, kernel_size=(3,), stride=(1,))\n",
      "  (9): ReLU()\n",
      "  (10): Flatten(start_dim=1, end_dim=-1)\n",
      "  (11): Linear(in_features=11, out_features=100, bias=True)\n",
      "  (12): ELU(alpha=1.0)\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (15): ELU(alpha=1.0)\n",
      "  (16): Dropout(p=0.3, inplace=False)\n",
      "  (17): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (18): ELU(alpha=1.0)\n",
      "  (19): Dropout(p=0.3, inplace=False)\n",
      "  (20): Linear(in_features=25, out_features=4, bias=True)\n",
      "  (21): Softmax(dim=None)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss :  tensor(1.3869) Accuracy :  tensor(0.2511) Val Loss :  tensor(1.3845) Val Accuracy :  tensor(0.2678)\n",
      "10 Loss :  tensor(1.1733) Accuracy :  tensor(0.5353) Val Loss :  tensor(1.1336) Val Accuracy :  tensor(0.5896)\n",
      "20 Loss :  tensor(1.0400) Accuracy :  tensor(0.6920) Val Loss :  tensor(1.0268) Val Accuracy :  tensor(0.7079)\n",
      "30 Loss :  tensor(0.9929) Accuracy :  tensor(0.7442) Val Loss :  tensor(0.9916) Val Accuracy :  tensor(0.7434)\n",
      "40 Loss :  tensor(0.9586) Accuracy :  tensor(0.7801) Val Loss :  tensor(0.9515) Val Accuracy :  tensor(0.7881)\n",
      "50 Loss :  tensor(0.9414) Accuracy :  tensor(0.7981) Val Loss :  tensor(0.9399) Val Accuracy :  tensor(0.7997)\n",
      "60 Loss :  tensor(0.9291) Accuracy :  tensor(0.8107) Val Loss :  tensor(0.9299) Val Accuracy :  tensor(0.8105)\n",
      "70 Loss :  tensor(0.9239) Accuracy :  tensor(0.8164) Val Loss :  tensor(0.9232) Val Accuracy :  tensor(0.8167)\n",
      "80 Loss :  tensor(0.9160) Accuracy :  tensor(0.8245) Val Loss :  tensor(0.9186) Val Accuracy :  tensor(0.8226)\n",
      "90 Loss :  tensor(0.9170) Accuracy :  tensor(0.8239) Val Loss :  tensor(0.9138) Val Accuracy :  tensor(0.8266)\n",
      "100 Loss :  tensor(0.9069) Accuracy :  tensor(0.8340) Val Loss :  tensor(0.9126) Val Accuracy :  tensor(0.8286)\n",
      "110 Loss :  tensor(0.9051) Accuracy :  tensor(0.8361) Val Loss :  tensor(0.9080) Val Accuracy :  tensor(0.8333)\n",
      "120 Loss :  tensor(0.8995) Accuracy :  tensor(0.8424) Val Loss :  tensor(0.9041) Val Accuracy :  tensor(0.8373)\n",
      "130 Loss :  tensor(0.8979) Accuracy :  tensor(0.8443) Val Loss :  tensor(0.8992) Val Accuracy :  tensor(0.8425)\n",
      "140 Loss :  tensor(0.9019) Accuracy :  tensor(0.8397) Val Loss :  tensor(0.9019) Val Accuracy :  tensor(0.8405)\n",
      "150 Loss :  tensor(0.8994) Accuracy :  tensor(0.8424) Val Loss :  tensor(0.8939) Val Accuracy :  tensor(0.8479)\n",
      "160 Loss :  tensor(0.8937) Accuracy :  tensor(0.8482) Val Loss :  tensor(0.8936) Val Accuracy :  tensor(0.8481)\n",
      "170 Loss :  tensor(0.8884) Accuracy :  tensor(0.8539) Val Loss :  tensor(0.8928) Val Accuracy :  tensor(0.8492)\n",
      "180 Loss :  tensor(0.8895) Accuracy :  tensor(0.8526) Val Loss :  tensor(0.8960) Val Accuracy :  tensor(0.8459)\n",
      "190 Loss :  tensor(0.8856) Accuracy :  tensor(0.8568) Val Loss :  tensor(0.8912) Val Accuracy :  tensor(0.8506)\n",
      "200 Loss :  tensor(0.8837) Accuracy :  tensor(0.8590) Val Loss :  tensor(0.8898) Val Accuracy :  tensor(0.8526)\n",
      "210 Loss :  tensor(0.8844) Accuracy :  tensor(0.8576) Val Loss :  tensor(0.8910) Val Accuracy :  tensor(0.8513)\n",
      "220 Loss :  tensor(0.8816) Accuracy :  tensor(0.8610) Val Loss :  tensor(0.8862) Val Accuracy :  tensor(0.8562)\n",
      "230 Loss :  tensor(0.8801) Accuracy :  tensor(0.8624) Val Loss :  tensor(0.8896) Val Accuracy :  tensor(0.8527)\n",
      "240 Loss :  tensor(0.8806) Accuracy :  tensor(0.8619) Val Loss :  tensor(0.8910) Val Accuracy :  tensor(0.8509)\n",
      "250 Loss :  tensor(0.8932) Accuracy :  tensor(0.8482) Val Loss :  tensor(0.8903) Val Accuracy :  tensor(0.8524)\n",
      "260 Loss :  tensor(0.8847) Accuracy :  tensor(0.8571) Val Loss :  tensor(0.8873) Val Accuracy :  tensor(0.8559)\n",
      "270 Loss :  tensor(0.8811) Accuracy :  tensor(0.8611) Val Loss :  tensor(0.8868) Val Accuracy :  tensor(0.8553)\n",
      "280 Loss :  tensor(0.8776) Accuracy :  tensor(0.8650) Val Loss :  tensor(0.8870) Val Accuracy :  tensor(0.8555)\n",
      "290 Loss :  tensor(0.8779) Accuracy :  tensor(0.8647) Val Loss :  tensor(0.8843) Val Accuracy :  tensor(0.8579)\n",
      "300 Loss :  tensor(0.8831) Accuracy :  tensor(0.8590) Val Loss :  tensor(0.8878) Val Accuracy :  tensor(0.8551)\n",
      "310 Loss :  tensor(0.8765) Accuracy :  tensor(0.8662) Val Loss :  tensor(0.8884) Val Accuracy :  tensor(0.8541)\n",
      "320 Loss :  tensor(0.8762) Accuracy :  tensor(0.8664) Val Loss :  tensor(0.8833) Val Accuracy :  tensor(0.8587)\n",
      "330 Loss :  tensor(0.8778) Accuracy :  tensor(0.8648) Val Loss :  tensor(0.8831) Val Accuracy :  tensor(0.8593)\n",
      "340 Loss :  tensor(0.8754) Accuracy :  tensor(0.8671) Val Loss :  tensor(0.8879) Val Accuracy :  tensor(0.8542)\n",
      "350 Loss :  tensor(0.8771) Accuracy :  tensor(0.8651) Val Loss :  tensor(0.8824) Val Accuracy :  tensor(0.8602)\n",
      "360 Loss :  tensor(0.8757) Accuracy :  tensor(0.8666) Val Loss :  tensor(0.8825) Val Accuracy :  tensor(0.8601)\n",
      "370 Loss :  tensor(0.8774) Accuracy :  tensor(0.8647) Val Loss :  tensor(0.8868) Val Accuracy :  tensor(0.8556)\n",
      "380 Loss :  tensor(0.8734) Accuracy :  tensor(0.8694) Val Loss :  tensor(0.8839) Val Accuracy :  tensor(0.8583)\n",
      "390 Loss :  tensor(0.8731) Accuracy :  tensor(0.8696) Val Loss :  tensor(0.8806) Val Accuracy :  tensor(0.8617)\n",
      "400 Loss :  tensor(0.8724) Accuracy :  tensor(0.8699) Val Loss :  tensor(0.8813) Val Accuracy :  tensor(0.8614)\n",
      "410 Loss :  tensor(0.8713) Accuracy :  tensor(0.8715) Val Loss :  tensor(0.8818) Val Accuracy :  tensor(0.8601)\n",
      "420 Loss :  tensor(0.8716) Accuracy :  tensor(0.8713) Val Loss :  tensor(0.8816) Val Accuracy :  tensor(0.8610)\n",
      "430 Loss :  tensor(0.8734) Accuracy :  tensor(0.8691) Val Loss :  tensor(0.8812) Val Accuracy :  tensor(0.8611)\n",
      "440 Loss :  tensor(0.8712) Accuracy :  tensor(0.8713) Val Loss :  tensor(0.8834) Val Accuracy :  tensor(0.8599)\n",
      "450 Loss :  tensor(0.8703) Accuracy :  tensor(0.8724) Val Loss :  tensor(0.8812) Val Accuracy :  tensor(0.8610)\n",
      "460 Loss :  tensor(0.8710) Accuracy :  tensor(0.8719) Val Loss :  tensor(0.8810) Val Accuracy :  tensor(0.8612)\n",
      "470 Loss :  tensor(0.8697) Accuracy :  tensor(0.8728) Val Loss :  tensor(0.8831) Val Accuracy :  tensor(0.8594)\n",
      "480 Loss :  tensor(0.8706) Accuracy :  tensor(0.8718) Val Loss :  tensor(0.8800) Val Accuracy :  tensor(0.8621)\n",
      "490 Loss :  tensor(0.8694) Accuracy :  tensor(0.8736) Val Loss :  tensor(0.8795) Val Accuracy :  tensor(0.8630)\n",
      "500 Loss :  tensor(0.8706) Accuracy :  tensor(0.8722) Val Loss :  tensor(0.8791) Val Accuracy :  tensor(0.8631)\n",
      "510 Loss :  tensor(0.8686) Accuracy :  tensor(0.8744) Val Loss :  tensor(0.8784) Val Accuracy :  tensor(0.8642)\n",
      "520 Loss :  tensor(0.8709) Accuracy :  tensor(0.8714) Val Loss :  tensor(0.8778) Val Accuracy :  tensor(0.8645)\n",
      "530 Loss :  tensor(0.8745) Accuracy :  tensor(0.8682) Val Loss :  tensor(0.8811) Val Accuracy :  tensor(0.8616)\n",
      "540 Loss :  tensor(0.8758) Accuracy :  tensor(0.8669) Val Loss :  tensor(0.8816) Val Accuracy :  tensor(0.8609)\n",
      "550 Loss :  tensor(0.8692) Accuracy :  tensor(0.8731) Val Loss :  tensor(0.8820) Val Accuracy :  tensor(0.8606)\n",
      "560 Loss :  tensor(0.8686) Accuracy :  tensor(0.8740) Val Loss :  tensor(0.8830) Val Accuracy :  tensor(0.8593)\n",
      "570 Loss :  tensor(0.8675) Accuracy :  tensor(0.8752) Val Loss :  tensor(0.8838) Val Accuracy :  tensor(0.8585)\n",
      "580 Loss :  tensor(0.8702) Accuracy :  tensor(0.8722) Val Loss :  tensor(0.8832) Val Accuracy :  tensor(0.8596)\n",
      "590 Loss :  tensor(0.8708) Accuracy :  tensor(0.8717) Val Loss :  tensor(0.8774) Val Accuracy :  tensor(0.8648)\n",
      "600 Loss :  tensor(0.8663) Accuracy :  tensor(0.8766) Val Loss :  tensor(0.8785) Val Accuracy :  tensor(0.8637)\n",
      "610 Loss :  tensor(0.8661) Accuracy :  tensor(0.8767) Val Loss :  tensor(0.8776) Val Accuracy :  tensor(0.8652)\n",
      "620 Loss :  tensor(0.8677) Accuracy :  tensor(0.8748) Val Loss :  tensor(0.8786) Val Accuracy :  tensor(0.8633)\n",
      "630 Loss :  tensor(0.8657) Accuracy :  tensor(0.8771) Val Loss :  tensor(0.8778) Val Accuracy :  tensor(0.8651)\n",
      "640 Loss :  tensor(0.8675) Accuracy :  tensor(0.8752) Val Loss :  tensor(0.8810) Val Accuracy :  tensor(0.8614)\n",
      "650 Loss :  tensor(0.8702) Accuracy :  tensor(0.8723) Val Loss :  tensor(0.8783) Val Accuracy :  tensor(0.8641)\n",
      "660 Loss :  tensor(0.8663) Accuracy :  tensor(0.8761) Val Loss :  tensor(0.8783) Val Accuracy :  tensor(0.8640)\n",
      "670 Loss :  tensor(0.8646) Accuracy :  tensor(0.8783) Val Loss :  tensor(0.8786) Val Accuracy :  tensor(0.8638)\n",
      "680 Loss :  tensor(0.8649) Accuracy :  tensor(0.8780) Val Loss :  tensor(0.8795) Val Accuracy :  tensor(0.8630)\n",
      "690 Loss :  tensor(0.8636) Accuracy :  tensor(0.8788) Val Loss :  tensor(0.8788) Val Accuracy :  tensor(0.8641)\n",
      "700 Loss :  tensor(0.8665) Accuracy :  tensor(0.8763) Val Loss :  tensor(0.8774) Val Accuracy :  tensor(0.8656)\n",
      "710 Loss :  tensor(0.8629) Accuracy :  tensor(0.8801) Val Loss :  tensor(0.8774) Val Accuracy :  tensor(0.8651)\n",
      "720 Loss :  tensor(0.8638) Accuracy :  tensor(0.8789) Val Loss :  tensor(0.8777) Val Accuracy :  tensor(0.8648)\n",
      "730 Loss :  tensor(0.8650) Accuracy :  tensor(0.8776) Val Loss :  tensor(0.8778) Val Accuracy :  tensor(0.8649)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740 Loss :  tensor(0.8639) Accuracy :  tensor(0.8788) Val Loss :  tensor(0.8780) Val Accuracy :  tensor(0.8643)\n",
      "750 Loss :  tensor(0.8679) Accuracy :  tensor(0.8750) Val Loss :  tensor(0.8779) Val Accuracy :  tensor(0.8645)\n",
      "760 Loss :  tensor(0.8637) Accuracy :  tensor(0.8792) Val Loss :  tensor(0.8794) Val Accuracy :  tensor(0.8629)\n",
      "770 Loss :  tensor(0.8664) Accuracy :  tensor(0.8762) Val Loss :  tensor(0.8776) Val Accuracy :  tensor(0.8651)\n",
      "780 Loss :  tensor(0.8624) Accuracy :  tensor(0.8803) Val Loss :  tensor(0.8774) Val Accuracy :  tensor(0.8660)\n",
      "790 Loss :  tensor(0.8633) Accuracy :  tensor(0.8795) Val Loss :  tensor(0.8780) Val Accuracy :  tensor(0.8647)\n",
      "800 Loss :  tensor(0.8631) Accuracy :  tensor(0.8798) Val Loss :  tensor(0.8781) Val Accuracy :  tensor(0.8642)\n",
      "810 Loss :  tensor(0.8629) Accuracy :  tensor(0.8799) Val Loss :  tensor(0.8792) Val Accuracy :  tensor(0.8636)\n",
      "820 Loss :  tensor(0.8638) Accuracy :  tensor(0.8791) Val Loss :  tensor(0.8771) Val Accuracy :  tensor(0.8656)\n",
      "830 Loss :  tensor(0.8645) Accuracy :  tensor(0.8782) Val Loss :  tensor(0.8798) Val Accuracy :  tensor(0.8625)\n",
      "840 Loss :  tensor(0.8621) Accuracy :  tensor(0.8807) Val Loss :  tensor(0.8800) Val Accuracy :  tensor(0.8622)\n",
      "850 Loss :  tensor(0.8693) Accuracy :  tensor(0.8729) Val Loss :  tensor(0.8770) Val Accuracy :  tensor(0.8655)\n",
      "860 Loss :  tensor(0.8612) Accuracy :  tensor(0.8817) Val Loss :  tensor(0.8775) Val Accuracy :  tensor(0.8651)\n",
      "870 Loss :  tensor(0.8624) Accuracy :  tensor(0.8804) Val Loss :  tensor(0.8763) Val Accuracy :  tensor(0.8665)\n",
      "880 Loss :  tensor(0.8627) Accuracy :  tensor(0.8801) Val Loss :  tensor(0.8766) Val Accuracy :  tensor(0.8662)\n",
      "890 Loss :  tensor(0.8623) Accuracy :  tensor(0.8802) Val Loss :  tensor(0.8784) Val Accuracy :  tensor(0.8639)\n",
      "900 Loss :  tensor(0.8604) Accuracy :  tensor(0.8824) Val Loss :  tensor(0.8768) Val Accuracy :  tensor(0.8657)\n",
      "910 Loss :  tensor(0.8602) Accuracy :  tensor(0.8827) Val Loss :  tensor(0.8773) Val Accuracy :  tensor(0.8653)\n",
      "920 Loss :  tensor(0.8604) Accuracy :  tensor(0.8824) Val Loss :  tensor(0.8772) Val Accuracy :  tensor(0.8651)\n",
      "930 Loss :  tensor(0.8630) Accuracy :  tensor(0.8797) Val Loss :  tensor(0.8802) Val Accuracy :  tensor(0.8622)\n",
      "940 Loss :  tensor(0.8639) Accuracy :  tensor(0.8791) Val Loss :  tensor(0.8764) Val Accuracy :  tensor(0.8660)\n",
      "950 Loss :  tensor(0.8696) Accuracy :  tensor(0.8727) Val Loss :  tensor(0.8768) Val Accuracy :  tensor(0.8654)\n",
      "960 Loss :  tensor(0.8622) Accuracy :  tensor(0.8804) Val Loss :  tensor(0.8801) Val Accuracy :  tensor(0.8625)\n",
      "970 Loss :  tensor(0.8597) Accuracy :  tensor(0.8831) Val Loss :  tensor(0.8769) Val Accuracy :  tensor(0.8655)\n",
      "980 Loss :  tensor(0.8590) Accuracy :  tensor(0.8839) Val Loss :  tensor(0.8767) Val Accuracy :  tensor(0.8659)\n",
      "990 Loss :  tensor(0.8601) Accuracy :  tensor(0.8827) Val Loss :  tensor(0.8782) Val Accuracy :  tensor(0.8642)\n"
     ]
    }
   ],
   "source": [
    "# Binary Crossentropy 손실 = loss(x,y) = BCE\n",
    "# Binary Crossentropy 손실 = loss(x,y) = BCE\n",
    "\n",
    "# [1, 1, 98000, 12] -> [1, 40, 97996, 11]\n",
    "# [1, 40, 97996, 11] -> [1, 40, 97992, 10]\n",
    "# [1, 40, 97992, 10] -> [1, 40, 97991, 9]\n",
    "# [1, 40, 97991, 9] -> [1, 40, 97990, 8]\n",
    "# [1, 40, 97989, 8] -> [1, 40, 97988, 8]\n",
    "\n",
    "model = nn.Sequential(nn.Conv1d(1,40, kernel_size=6),nn.ReLU(), \n",
    "                      nn.Conv1d(40, 40, kernel_size=3), nn.ReLU(),\n",
    "                      nn.Conv1d(40, 40, kernel_size=3), nn.ReLU(),\n",
    "                      nn.Conv1d(40, 40, kernel_size=3), nn.ReLU(),\n",
    "                      nn.Conv1d(40, 1, kernel_size=3), nn.ReLU(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(11, 100), nn.ELU(), nn.Dropout(0.3),\n",
    "                      nn.Linear(100, 50), nn.ELU(),nn.Dropout(0.3),\n",
    "                      nn.Linear(50, 25), nn.ELU(),nn.Dropout(0.3),\n",
    "                     nn.Linear(25, Y.shape[1]), nn.Softmax())\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters() ,lr = Learning_Rate)\n",
    "Loss_fun = torch.nn.CrossEntropyLoss()\n",
    "Loss = np.zeros((num_epoch,1))\n",
    "Val_Loss = np.zeros((num_epoch,1))\n",
    "Accuracy = np.zeros((num_epoch,1))\n",
    "Val_Accuracy = np.zeros((num_epoch,1))\n",
    "#학습\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_re)\n",
    "    loss = Loss_fun(output,Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Accuracy Calculate\n",
    "    output_not_one_hot_encoding=torch.argmax(output,dim=1)\n",
    "    accuracy = torch.divide(torch.count_nonzero(torch.eq(output_not_one_hot_encoding,\n",
    "                                                         Y_not_one_hot_encoding)),Y_not_one_hot_encoding.shape[0])\n",
    "    with torch.no_grad():\n",
    "        val_output = model(Val_X_re)\n",
    "        val_loss = Loss_fun(val_output,Val_Y)\n",
    "        val_output_not_one_hot_encoding=torch.argmax(val_output,dim=1)\n",
    "        val_accuracy = torch.divide(torch.count_nonzero(torch.eq(val_output_not_one_hot_encoding,\n",
    "                                                         Val_Y_not_one_hot_encoding)),Val_Y_not_one_hot_encoding.shape[0])\n",
    "    Loss[i,0] = loss.data\n",
    "    Accuracy[i,0] = accuracy\n",
    "    Val_Loss[i,0] = val_loss.data\n",
    "    Val_Accuracy[i,0] = val_accuracy\n",
    "    if i % 10 == 0:\n",
    "        print(i,\"Loss : \",loss.data,\"Accuracy : \",accuracy.data,\"Val Loss : \",val_loss.data,\"Val Accuracy : \",val_accuracy.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67852e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0,  ..., 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "Predict = model(TEST_re)\n",
    "Predict_not_one_hot_encoding = torch.argmax(Predict,dim=1)\n",
    "print(Predict_not_one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d5dbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"G:/내 드라이브/연구실/PyTorch/6주차/Test_Predict.csv\",Predict_not_one_hot_encoding,delimiter=\",\",fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196785fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
